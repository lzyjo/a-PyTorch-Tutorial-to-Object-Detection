{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lzyjo/a-PyTorch-Tutorial-to-Object-Detection/blob/Original-modified-to-work/Model_Run_Original_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1-5zEAd_ve"
      },
      "source": [
        "# Working directory and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzPE7m2JkI3r",
        "outputId": "7b8a5556-7f12-414b-a64e-6554fe0d30ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Mount Google Drive at '/content/drive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcTPGmMHclaO",
        "outputId": "d6b7918e-1c9b-42a6-c23b-bae2dace3c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# import and extract dataset\n",
        "\n",
        "import tarfile\n",
        "\n",
        "# Define the file_path variable with the actual path to your tar file\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtest_06-Nov-2007.tar\"  # Replace with the correct path\n",
        "\n",
        "# Open the tar file in read mode ('r')\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    # Extract all members of the archive to the current working directory\n",
        "    tar.extractall()\n",
        "    print('Done')\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtrainval_06-Nov-2007.tar\"  # Replace with the correct path\n",
        "\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    tar.extractall()\n",
        "    print('Done')\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtrainval_11-May-2012.tar\"  # Replace with the correct path\n",
        "\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    tar.extractall()\n",
        "    print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b Original-modified-to-work --single-branch https://github.com/lzyjo/a-PyTorch-Tutorial-to-Object-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvwfRUhjM-Qm",
        "outputId": "fe471a24-5cf0-4091-f085-cee5b1bba157"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'a-PyTorch-Tutorial-to-Object-Detection'...\n",
            "remote: Enumerating objects: 272, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 272 (delta 73), reused 64 (delta 58), pack-reused 181 (from 1)\u001b[K\n",
            "Receiving objects: 100% (272/272), 175.98 MiB | 6.83 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRzJn3EdQHNj",
        "outputId": "a8f65f39-6cc4-483d-eaa3-d79654ab3894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully moved '/content/VOCdevkit' to '/content/a-PyTorch-Tutorial-to-Object-Detection'\n"
          ]
        }
      ],
      "source": [
        "# prompt: move VOCdevkit folder into /content/a-PyTorch-Tutorial-to-Object-Detection-master\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"/content/VOCdevkit\"  # Replace with the actual path to your VOCdevkit folder\n",
        "destination_path = \"/content/a-PyTorch-Tutorial-to-Object-Detection\"\n",
        "\n",
        "# Check if the source directory exists\n",
        "if os.path.exists(source_path):\n",
        "    try:\n",
        "        # Use shutil.move to move the directory\n",
        "        shutil.move(source_path, destination_path)\n",
        "        print(f\"Successfully moved '{source_path}' to '{destination_path}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error moving directory: {e}\")\n",
        "else:\n",
        "    print(f\"Source directory '{source_path}' not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVOlFRtaR595",
        "outputId": "2f669ad8-ce31-4cb9-bcf5-f18013eccaf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection\n"
          ]
        }
      ],
      "source": [
        "%cd /content/a-PyTorch-Tutorial-to-Object-Detection\n",
        "#change cwd to appropriate one\n",
        "\n",
        "#don't need this but maybe useful for other projects:\n",
        "#!git clone https://github.com/lzyjo/a-PyTorch-Tutorial-to-Object-Detection.git #clone repo with all .py files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import utils"
      ],
      "metadata": {
        "id": "GoM-dOg1PKpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import create_data_lists"
      ],
      "metadata": {
        "id": "dr7KaSIKi6gV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_data_lists(voc07_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2007',\n",
        "                  voc12_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2012',\n",
        "                  output_folder='./')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hgUuOIQsv2Q",
        "outputId": "f1bc799b-a34f-48bb-9bcf-b100d27397e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 16551 training images containing a total of 49653 objects. Files have been saved to /content/a-PyTorch-Tutorial-to-Object-Detection.\n",
            "\n",
            "There are 4952 test images containing a total of 14856 objects. Files have been saved to /content/a-PyTorch-Tutorial-to-Object-Detection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import model\n",
        "import train\n",
        "import eval\n",
        "import detect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d11uKg3sBurU",
        "outputId": "202bdc88-69d4-4905-9691-ea38ac4abb20"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/detect.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'model.SSD300' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded checkpoint from epoch 232.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Torch CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdUkOL8r34lV",
        "outputId": "779c664b-57e5-4324-9b0c-8338418f9dcb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available. Using CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate and Detect"
      ],
      "metadata": {
        "id": "uaZKzJpYPNrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from eval import *"
      ],
      "metadata": {
        "id": "ZYn9bVbBDYC7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhUdWqjFx0Pr",
        "outputId": "232f1d45-5b54-4f9c-d9df-225b64f37738"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/78 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/a-PyTorch-Tutorial-to-Object-Detection/model.py:501: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
            "/content/a-PyTorch-Tutorial-to-Object-Detection/model.py:503: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  image_scores.append(class_scores[1 - suppress])\n",
            "Evaluating: 100%|██████████| 78/78 [2:30:37<00:00, 115.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'aeroplane': 0.790989875793457,\n",
            " 'bicycle': 0.8309301733970642,\n",
            " 'bird': 0.7649813294410706,\n",
            " 'boat': 0.7225903868675232,\n",
            " 'bottle': 0.46215584874153137,\n",
            " 'bus': 0.8695299625396729,\n",
            " 'car': 0.8656850457191467,\n",
            " 'cat': 0.883727490901947,\n",
            " 'chair': 0.5916000604629517,\n",
            " 'cow': 0.8243222832679749,\n",
            " 'diningtable': 0.758436381816864,\n",
            " 'dog': 0.854961633682251,\n",
            " 'horse': 0.8753499984741211,\n",
            " 'motorbike': 0.8315761685371399,\n",
            " 'person': 0.7886016964912415,\n",
            " 'pottedplant': 0.5129949450492859,\n",
            " 'sheep': 0.7923182845115662,\n",
            " 'sofa': 0.7978971004486084,\n",
            " 'train': 0.8620267510414124,\n",
            " 'tvmonitor': 0.7486801743507385}\n",
            "\n",
            "Mean Average Precision (mAP): 0.771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detect import *"
      ],
      "metadata": {
        "id": "sR9RvJWwny95"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "img_path = '/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg'\n",
        "original_image = PIL.Image.open(img_path, mode='r')\n",
        "original_image = original_image.convert('RGB')\n",
        "\n",
        "detect(original_image, min_score=0.2, max_overlap=0.5, top_k=200).show() #detect(original_image, min_score, max_overlap, top_k, suppress=None)"
      ],
      "metadata": {
        "id": "Qy_R5emayZ7J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "cc883900-fee3-4a68-8c56-ac8e38269e00"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/model.py:501: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
            "/content/a-PyTorch-Tutorial-to-Object-Detection/model.py:503: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  image_scores.append(class_scores[1 - suppress])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "cannot open resource",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e5c7241d8161>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_overlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#detect(original_image, min_score, max_overlap, top_k, suppress=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/a-PyTorch-Tutorial-to-Object-Detection/detect.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(original_image, min_score, max_overlap, top_k, suppress)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mannotated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./calibril.ttf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Suppress specific classes, if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mfreetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStrOrBytesPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0mload_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             self.font = core.getfont(\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             )\n",
            "\u001b[0;31mOSError\u001b[0m: cannot open resource"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Model-Run_Original-code.ipynb",
      "authorship_tag": "ABX9TyNpDbs1UDo6X9OSe/RfMDll",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}