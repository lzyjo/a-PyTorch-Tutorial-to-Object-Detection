{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lzyjo/a-PyTorch-Tutorial-to-Object-Detection/blob/CPU-modified-to-run/CPU-modified-to-run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "# Notes\n",
        "\n",
        "**Changes**\n",
        "*   Changed checkpoint to point to relevant file path in cwd\n",
        "\n",
        "\n",
        "**Progress**\n",
        "*   Works running on cpu (finished evaluating!) until detect - can't get pillow to work. Also tried using matlabplot but then the font error still comes up.\n",
        "\n"
      ],
      "metadata": {
        "id": "gR-t_LCyhxD8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1-5zEAd_ve"
      },
      "source": [
        "# Working directory and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzPE7m2JkI3r",
        "outputId": "7f846e15-919a-44d8-8b94-c077cac95e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Mount Google Drive at '/content/drive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcTPGmMHclaO",
        "outputId": "db232510-4202-47d2-a945-82cb37093a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# import and extract dataset\n",
        "\n",
        "import tarfile\n",
        "\n",
        "# Define the file_path variable with the actual path to your tar file\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtest_06-Nov-2007.tar\"  # Replace with the correct path\n",
        "\n",
        "# Open the tar file in read mode ('r')\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    # Extract all members of the archive to the current working directory\n",
        "    tar.extractall()\n",
        "    print('Done')\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtrainval_06-Nov-2007.tar\"  # Replace with the correct path\n",
        "\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    tar.extractall()\n",
        "    print('Done')\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtrainval_11-May-2012.tar\"  # Replace with the correct path\n",
        "\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    tar.extractall()\n",
        "    print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b CPU-modified-to-run --single-branch https://github.com/lzyjo/a-PyTorch-Tutorial-to-Object-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvwfRUhjM-Qm",
        "outputId": "288688c2-d4f5-40f1-b62c-8a0c26e3b26e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'a-PyTorch-Tutorial-to-Object-Detection'...\n",
            "remote: Enumerating objects: 299, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/111)\u001b[K\rremote: Counting objects:   1% (2/111)\u001b[K\rremote: Counting objects:   2% (3/111)\u001b[K\rremote: Counting objects:   3% (4/111)\u001b[K\rremote: Counting objects:   4% (5/111)\u001b[K\rremote: Counting objects:   5% (6/111)\u001b[K\rremote: Counting objects:   6% (7/111)\u001b[K\rremote: Counting objects:   7% (8/111)\u001b[K\rremote: Counting objects:   8% (9/111)\u001b[K\rremote: Counting objects:   9% (10/111)\u001b[K\rremote: Counting objects:  10% (12/111)\u001b[K\rremote: Counting objects:  11% (13/111)\u001b[K\rremote: Counting objects:  12% (14/111)\u001b[K\rremote: Counting objects:  13% (15/111)\u001b[K\rremote: Counting objects:  14% (16/111)\u001b[K\rremote: Counting objects:  15% (17/111)\u001b[K\rremote: Counting objects:  16% (18/111)\u001b[K\rremote: Counting objects:  17% (19/111)\u001b[K\rremote: Counting objects:  18% (20/111)\u001b[K\rremote: Counting objects:  19% (22/111)\u001b[K\rremote: Counting objects:  20% (23/111)\u001b[K\rremote: Counting objects:  21% (24/111)\u001b[K\rremote: Counting objects:  22% (25/111)\u001b[K\rremote: Counting objects:  23% (26/111)\u001b[K\rremote: Counting objects:  24% (27/111)\u001b[K\rremote: Counting objects:  25% (28/111)\u001b[K\rremote: Counting objects:  26% (29/111)\u001b[K\rremote: Counting objects:  27% (30/111)\u001b[K\rremote: Counting objects:  28% (32/111)\u001b[K\rremote: Counting objects:  29% (33/111)\u001b[K\rremote: Counting objects:  30% (34/111)\u001b[K\rremote: Counting objects:  31% (35/111)\u001b[K\rremote: Counting objects:  32% (36/111)\u001b[K\rremote: Counting objects:  33% (37/111)\u001b[K\rremote: Counting objects:  34% (38/111)\u001b[K\rremote: Counting objects:  35% (39/111)\u001b[K\rremote: Counting objects:  36% (40/111)\u001b[K\rremote: Counting objects:  37% (42/111)\u001b[K\rremote: Counting objects:  38% (43/111)\u001b[K\rremote: Counting objects:  39% (44/111)\u001b[K\rremote: Counting objects:  40% (45/111)\u001b[K\rremote: Counting objects:  41% (46/111)\u001b[K\rremote: Counting objects:  42% (47/111)\u001b[K\rremote: Counting objects:  43% (48/111)\u001b[K\rremote: Counting objects:  44% (49/111)\u001b[K\rremote: Counting objects:  45% (50/111)\u001b[K\rremote: Counting objects:  46% (52/111)\u001b[K\rremote: Counting objects:  47% (53/111)\u001b[K\rremote: Counting objects:  48% (54/111)\u001b[K\rremote: Counting objects:  49% (55/111)\u001b[K\rremote: Counting objects:  50% (56/111)\u001b[K\rremote: Counting objects:  51% (57/111)\u001b[K\rremote: Counting objects:  52% (58/111)\u001b[K\rremote: Counting objects:  53% (59/111)\u001b[K\rremote: Counting objects:  54% (60/111)\u001b[K\rremote: Counting objects:  55% (62/111)\u001b[K\rremote: Counting objects:  56% (63/111)\u001b[K\rremote: Counting objects:  57% (64/111)\u001b[K\rremote: Counting objects:  58% (65/111)\u001b[K\rremote: Counting objects:  59% (66/111)\u001b[K\rremote: Counting objects:  60% (67/111)\u001b[K\rremote: Counting objects:  61% (68/111)\u001b[K\rremote: Counting objects:  62% (69/111)\u001b[K\rremote: Counting objects:  63% (70/111)\u001b[K\rremote: Counting objects:  64% (72/111)\u001b[K\rremote: Counting objects:  65% (73/111)\u001b[K\rremote: Counting objects:  66% (74/111)\u001b[K\rremote: Counting objects:  67% (75/111)\u001b[K\rremote: Counting objects:  68% (76/111)\u001b[K\rremote: Counting objects:  69% (77/111)\u001b[K\rremote: Counting objects:  70% (78/111)\u001b[K\rremote: Counting objects:  71% (79/111)\u001b[K\rremote: Counting objects:  72% (80/111)\u001b[K\rremote: Counting objects:  73% (82/111)\u001b[K\rremote: Counting objects:  74% (83/111)\u001b[K\rremote: Counting objects:  75% (84/111)\u001b[K\rremote: Counting objects:  76% (85/111)\u001b[K\rremote: Counting objects:  77% (86/111)\u001b[K\rremote: Counting objects:  78% (87/111)\u001b[K\rremote: Counting objects:  79% (88/111)\u001b[K\rremote: Counting objects:  80% (89/111)\u001b[K\rremote: Counting objects:  81% (90/111)\u001b[K\rremote: Counting objects:  82% (92/111)\u001b[K\rremote: Counting objects:  83% (93/111)\u001b[K\rremote: Counting objects:  84% (94/111)\u001b[K\rremote: Counting objects:  85% (95/111)\u001b[K\rremote: Counting objects:  86% (96/111)\u001b[K\rremote: Counting objects:  87% (97/111)\u001b[K\rremote: Counting objects:  88% (98/111)\u001b[K\rremote: Counting objects:  89% (99/111)\u001b[K\rremote: Counting objects:  90% (100/111)\u001b[K\rremote: Counting objects:  91% (102/111)\u001b[K\rremote: Counting objects:  92% (103/111)\u001b[K\rremote: Counting objects:  93% (104/111)\u001b[K\rremote: Counting objects:  94% (105/111)\u001b[K\rremote: Counting objects:  95% (106/111)\u001b[K\rremote: Counting objects:  96% (107/111)\u001b[K\rremote: Counting objects:  97% (108/111)\u001b[K\rremote: Counting objects:  98% (109/111)\u001b[K\rremote: Counting objects:  99% (110/111)\u001b[K\rremote: Counting objects: 100% (111/111)\u001b[K\rremote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 299 (delta 89), reused 58 (delta 58), pack-reused 188 (from 2)\u001b[K\n",
            "Receiving objects: 100% (299/299), 176.00 MiB | 40.45 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRzJn3EdQHNj",
        "outputId": "6c552d75-c072-4c6e-c0a4-06d68335b8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully moved '/content/VOCdevkit' to '/content/a-PyTorch-Tutorial-to-Object-Detection'\n"
          ]
        }
      ],
      "source": [
        "# prompt: move VOCdevkit folder into /content/a-PyTorch-Tutorial-to-Object-Detection-master\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"/content/VOCdevkit\"  # Replace with the actual path to your VOCdevkit folder\n",
        "destination_path = \"/content/a-PyTorch-Tutorial-to-Object-Detection\"\n",
        "\n",
        "# Check if the source directory exists\n",
        "if os.path.exists(source_path):\n",
        "    try:\n",
        "        # Use shutil.move to move the directory\n",
        "        shutil.move(source_path, destination_path)\n",
        "        print(f\"Successfully moved '{source_path}' to '{destination_path}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error moving directory: {e}\")\n",
        "else:\n",
        "    print(f\"Source directory '{source_path}' not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVOlFRtaR595",
        "outputId": "9a972adf-82ba-4495-91bf-c624bef91ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection\n"
          ]
        }
      ],
      "source": [
        "%cd /content/a-PyTorch-Tutorial-to-Object-Detection\n",
        "#change cwd to appropriate one\n",
        "\n",
        "#don't need this but maybe useful for other projects:\n",
        "#!git clone https://github.com/lzyjo/a-PyTorch-Tutorial-to-Object-Detection.git #clone repo with all .py files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/a-PyTorch-Tutorial-to-Object-Detection/a-PyTorch-Tutorial-to-Object-Detection"
      ],
      "metadata": {
        "id": "gPiChiIrzMUF",
        "outputId": "b8f9b18a-3a35-4f87-a37e-6e04f5a1bf43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/a-PyTorch-Tutorial-to-Object-Detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import utils"
      ],
      "metadata": {
        "id": "GoM-dOg1PKpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import create_data_lists"
      ],
      "metadata": {
        "id": "dr7KaSIKi6gV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ffe9a7-d75c-4fed-8497-4b7290ee7800"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/a-PyTorch-Tutorial-to-Object-Detection/utils.py:570: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if d.__name__ is 'adjust_hue':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_data_lists(voc07_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2007',\n",
        "                  voc12_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2012',\n",
        "                  output_folder='./')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "4hgUuOIQsv2Q",
        "outputId": "42489018-fe53-44e7-f42c-04abc393a959"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-502f895f4087>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m create_data_lists(voc07_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2007',\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mvoc12_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2012'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   output_folder='./')\n",
            "\u001b[0;32m/content/a-PyTorch-Tutorial-to-Object-Detection/a-PyTorch-Tutorial-to-Object-Detection/utils.py\u001b[0m in \u001b[0;36mcreate_data_lists\u001b[0;34m(voc07_path, voc12_path, output_folder)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Find IDs of images in training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ImageSets/Main/trainval.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"To Avoid RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False\" indicates that the model you are trying to load was saved on a machine with a CUDA-enabled GPU, but your current environment does not have a CUDA-enabled GPU.\n",
        "The line checkpoint = torch.load(checkpoint) in eval.py is attempting to load the model checkpoint. Because the checkpoint was likely saved on a GPU, it expects to load onto a GPU. Since you're likely running in an environment without a GPU (like Google Colab without a GPU runtime), this causes the error\"\"\"\n",
        "\n",
        "#Locate the eval.py and detect.py files and modify them\n",
        "# Example: Assuming eval.py and detect.py are in the current directory\n",
        "# In a real scenario, replace './eval.py' and './detect.py' with the actual paths\n",
        "!sed -i \"s/checkpoint = torch.load(checkpoint)/checkpoint = torch.load(checkpoint, map_location=torch.device('cpu'))/g\" ./eval.py\n",
        "!sed -i \"s/checkpoint = torch.load(checkpoint)/checkpoint = torch.load(checkpoint, map_location=torch.device('cpu'))/g\" ./detect.py\n",
        "print('done!')"
      ],
      "metadata": {
        "id": "m2VPIwD8jEZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import *\n",
        "from utils import *\n",
        "from train import *"
      ],
      "metadata": {
        "id": "d11uKg3sBurU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Torch CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdUkOL8r34lV",
        "outputId": "bf11ba5a-24df-497b-f76b-5f8a6bf52958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available. Using CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate and Detect"
      ],
      "metadata": {
        "id": "uaZKzJpYPNrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from eval import *"
      ],
      "metadata": {
        "id": "ZYn9bVbBDYC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader, model)"
      ],
      "metadata": {
        "id": "UhUdWqjFx0Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detect import *"
      ],
      "metadata": {
        "id": "sR9RvJWwny95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg'\n",
        "original_image = PIL.Image.open(img_path, mode='r')\n",
        "original_image = original_image.convert('RGB')\n",
        "\n",
        "detect(original_image, min_score=0.2, max_overlap=0.5, top_k=200) #detect(original_image, min_score, max_overlap, top_k, suppress=None)"
      ],
      "metadata": {
        "id": "Qy_R5emayZ7J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "63c9aad6-544a-459c-b62b-3718131a4ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "cannot open resource",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-11ac3d122b41>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_overlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#detect(original_image, min_score, max_overlap, top_k, suppress=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/a-PyTorch-Tutorial-to-Object-Detection/detect.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(original_image, min_score, max_overlap, top_k, suppress)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mannotated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./calibril.ttf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Suppress specific classes, if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mfreetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStrOrBytesPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0mload_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             self.font = core.getfont(\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             )\n",
            "\u001b[0;31mOSError\u001b[0m: cannot open resource"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check if pillow installed, and check if pillow Image, ImageDraw, ImageFont are installed\n",
        "\n",
        "!pip install Pillow\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageDraw, ImageFont\n",
        "    print(\"Pillow and its modules (Image, ImageDraw, ImageFont) are installed.\")\n",
        "except ImportError:\n",
        "    print(\"Pillow or one of its required modules is not installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGwO2rH30gci",
        "outputId": "393aefde-111e-444b-a1e9-71801c318bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Pillow and its modules (Image, ImageDraw, ImageFont) are installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFont"
      ],
      "metadata": {
        "id": "CfRrVitaw5Pk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "font = ImageFont.truetype('futura medium bt.ttf')"
      ],
      "metadata": {
        "id": "WFa_YxT6xJKj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* download a .ttf file to use"
      ],
      "metadata": {
        "id": "PiDzxQqjyLdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BU2XJ3dMyVj6"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Model-Run_Original-code.ipynb",
      "authorship_tag": "ABX9TyOaYO6LcwXkE+RNU6Wt0oEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}