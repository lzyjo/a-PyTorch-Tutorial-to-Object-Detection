{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lzyjo/a-PyTorch-Tutorial-to-Object-Detection/blob/GPU-modified-to-run/GPU-modified-to-run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes\n",
        "\n",
        "**Changes**\n",
        "*   Changed checkpoint to point to relevant file path in cwd\n",
        "*   Changed all device to cuda\n",
        "*   Changed torch.LongTensor to torch.arange\n",
        "*   Changed all torch.xTensors to CUDA-friendly format\n",
        "\n",
        "**Progress**\n",
        "*   When changed all torch.xTensors to CUDA-friendly format, returns RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
        "*   Seems to be same problem as CPU-run with detect.py - PIL not working\n",
        "*   List item\n",
        "\n",
        "Levi notes:\n",
        "* use import module\n",
        "* not from module import *\n"
      ],
      "metadata": {
        "id": "8LDzyfJW5NUC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1-5zEAd_ve"
      },
      "source": [
        "# Working directory and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzPE7m2JkI3r",
        "outputId": "c67859fd-8f24-4425-c648-e313416d7bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Mount Google Drive at '/content/drive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcTPGmMHclaO",
        "outputId": "358aea1e-22a2-4740-9f01-1115ee0b3d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# import and extract dataset\n",
        "\n",
        "import tarfile\n",
        "\n",
        "# Define the file_path variable with the actual path to your tar file\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtest_06-Nov-2007.tar\"  # Replace with the correct path\n",
        "\n",
        "# Open the tar file in read mode ('r')\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    # Extract all members of the archive to the current working directory\n",
        "    tar.extractall()\n",
        "    print('Done')\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtrainval_06-Nov-2007.tar\"  # Replace with the correct path\n",
        "\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    tar.extractall()\n",
        "    print('Done')\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtrainval_11-May-2012.tar\"  # Replace with the correct path\n",
        "\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    tar.extractall()\n",
        "    print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b GPU-modified-to-run --single-branch https://github.com/lzyjo/a-PyTorch-Tutorial-to-Object-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvwfRUhjM-Qm",
        "outputId": "61c912c3-6ff0-4a3c-ce10-8c72dcc7fb16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'a-PyTorch-Tutorial-to-Object-Detection'...\n",
            "remote: Enumerating objects: 324, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 324 (delta 102), reused 67 (delta 67), pack-reused 198 (from 2)\u001b[K\n",
            "Receiving objects: 100% (324/324), 176.02 MiB | 30.44 MiB/s, done.\n",
            "Resolving deltas: 100% (160/160), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRzJn3EdQHNj",
        "outputId": "41cb9678-0d00-4915-8f77-9deea297ea0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully moved '/content/VOCdevkit' to '/content/a-PyTorch-Tutorial-to-Object-Detection'\n"
          ]
        }
      ],
      "source": [
        "# prompt: move VOCdevkit folder into /content/a-PyTorch-Tutorial-to-Object-Detection-master\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"/content/VOCdevkit\"  # Replace with the actual path to your VOCdevkit folder\n",
        "destination_path = \"/content/a-PyTorch-Tutorial-to-Object-Detection\"\n",
        "\n",
        "# Check if the source directory exists\n",
        "if os.path.exists(source_path):\n",
        "    try:\n",
        "        # Use shutil.move to move the directory\n",
        "        shutil.move(source_path, destination_path)\n",
        "        print(f\"Successfully moved '{source_path}' to '{destination_path}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error moving directory: {e}\")\n",
        "else:\n",
        "    print(f\"Source directory '{source_path}' not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVOlFRtaR595",
        "outputId": "c5d4f037-a33b-4ce6-9d7d-6ec301b6a456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection\n"
          ]
        }
      ],
      "source": [
        "%cd /content/a-PyTorch-Tutorial-to-Object-Detection\n",
        "#change cwd to appropriate one\n",
        "\n",
        "#don't need this but maybe useful for other projects:\n",
        "#!git clone https://github.com/lzyjo/a-PyTorch-Tutorial-to-Object-Detection.git #clone repo with all .py files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import utils"
      ],
      "metadata": {
        "id": "GoM-dOg1PKpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import * #includes from utils import create_data_lists for datalist creation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr7KaSIKi6gV",
        "outputId": "b4a22c8f-f2f9-4dea-b7b2-8bd114cdab98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/utils.py:570: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if d.__name__ is 'adjust_hue':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_data_lists(voc07_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2007',\n",
        "                  voc12_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2012',\n",
        "                  output_folder='/content/a-PyTorch-Tutorial-to-Object-Detection')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hgUuOIQsv2Q",
        "outputId": "85030f8c-aa34-4181-a31e-892fdf7c97e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 16551 training images containing a total of 49653 objects. Files have been saved to /content/a-PyTorch-Tutorial-to-Object-Detection.\n",
            "\n",
            "There are 4952 test images containing a total of 14856 objects. Files have been saved to /content/a-PyTorch-Tutorial-to-Object-Detection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Torch CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6296c90c-c3e4-40cf-8204-1cf3ff234048",
        "id": "PTe1aBw-71k9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Using GPU.\n",
            "Torch CUDA version: 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import *\n",
        "from model import *\n",
        "from train import *\n",
        "from eval import * #changed checkpoint file directory in detect.py to file path in cwd\n",
        "from detect import * #changed checkpoint file directory in detect.py to file path in cwd"
      ],
      "metadata": {
        "id": "H9XV9EkitXng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb4fcd9-a12d-49f0-e00c-6f6e9da972d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/eval.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'model.SSD300' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/a-PyTorch-Tutorial-to-Object-Detection/detect.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded checkpoint from epoch 232.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## levi notes\n",
        "\n",
        "* when from module import *, torch is imported multiple times, which may be causing the issues\n",
        "* code is not designed to work with .ipynb"
      ],
      "metadata": {
        "id": "3_HZNvZ8qoXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate and Detect"
      ],
      "metadata": {
        "id": "uaZKzJpYPNrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from eval import *"
      ],
      "metadata": {
        "id": "xLH-WIib-TJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UhUdWqjFx0Pr",
        "outputId": "4738cd2f-fa92-4ec7-b8dc-7ab279c62bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/78 [00:00<?, ?it/s]/content/a-PyTorch-Tutorial-to-Object-Detection/datasets.py:42: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  boxes = torch.cuda.FloatTensor(objects['boxes'])  # (n_objects, 4)\n",
            "Evaluating:   0%|          | 0/78 [00:00<?, ?it/s]/content/a-PyTorch-Tutorial-to-Object-Detection/datasets.py:42: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  boxes = torch.cuda.FloatTensor(objects['boxes'])  # (n_objects, 4)\n",
            "/content/a-PyTorch-Tutorial-to-Object-Detection/datasets.py:42: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  boxes = torch.cuda.FloatTensor(objects['boxes'])  # (n_objects, 4)\n",
            "/content/a-PyTorch-Tutorial-to-Object-Detection/datasets.py:42: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  boxes = torch.cuda.FloatTensor(objects['boxes'])  # (n_objects, 4)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/a-PyTorch-Tutorial-to-Object-Detection/datasets.py\", line 42, in __getitem__\n    boxes = torch.cuda.FloatTensor(objects['boxes'])  # (n_objects, 4)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0a3b9d898ba5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/a-PyTorch-Tutorial-to-Object-Detection/eval.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(test_loader, model)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdifficulties\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Evaluating'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (N, 3, 300, 300)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/a-PyTorch-Tutorial-to-Object-Detection/datasets.py\", line 42, in __getitem__\n    boxes = torch.cuda.FloatTensor(objects['boxes'])  # (n_objects, 4)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yJ2F7w7Roaxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/path/to/ima.ge'\n",
        "original_image = PIL.Image.open(img_path, mode='r')\n",
        "original_image = original_image.convert('RGB')\n",
        "\n",
        "detect(original_image, min_score=0.2, max_overlap=0.5, top_k=200).show() #detect(original_image, min_score, max_overlap, top_k, suppress=None)"
      ],
      "metadata": {
        "id": "Qy_R5emayZ7J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0fbca58d-8a7c-41ad-8f39-064ee251d364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PIL' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4e974c2fd744>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/path/to/ima.ge'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_overlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#detect(original_image, min_score, max_overlap, top_k, suppress=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PIL' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run files as instructyed"
      ],
      "metadata": {
        "id": "ezqwbomwtY6c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AyePY374r6yn",
        "outputId": "9265f207-d2ab-4cd0-cce8-2a23e43692e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:03<00:00, 173MB/s]\n",
            "\n",
            "Loaded base model.\n",
            "\n",
            "/content/a-PyTorch-Tutorial-to-Object-Detection/model.py:339: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  self.rescale_factors = nn.Parameter(torch.cuda.FloatTensor(1, 512, 1, 1))  # there are 512 channels in conv4_3_feats\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/a-PyTorch-Tutorial-to-Object-Detection/train.py\", line 160, in <module>\n",
            "    main()\n",
            "  File \"/content/a-PyTorch-Tutorial-to-Object-Detection/train.py\", line 89, in main\n",
            "    train(train_loader=train_loader,\n",
            "  File \"/content/a-PyTorch-Tutorial-to-Object-Detection/train.py\", line 118, in train\n",
            "    for i, (images, boxes, labels, _) in enumerate(train_loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 715, in reraise\n",
            "    raise exception\n",
            "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/a-PyTorch-Tutorial-to-Object-Detection/datasets.py\", line 42, in __getitem__\n",
            "    boxes = torch.cuda.FloatTensor(objects['boxes'])  # (n_objects, 4)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py"
      ],
      "metadata": {
        "id": "BhcJY1k0so7B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MzvBLQCKwwKU",
        "XMccxmZOwzcc",
        "LVgbA6lwDqLQ",
        "UW11MyYNIURS",
        "eSf0WOWvJjEh",
        "OROMHJITLoMx",
        "6Q6HpUa5MDeh",
        "4IhbRRNnMoBp",
        "0uwD4YI5N84Y",
        "TmVGBbN_hVfd"
      ],
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgjvEGw1Hm3aBcryLj7S0y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}