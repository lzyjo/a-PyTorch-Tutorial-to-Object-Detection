{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lzyjo/a-PyTorch-Tutorial-to-Object-Detection/blob/testing-torch.cuda.xTenspr/GPU-modified-to-run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes\n",
        "\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8LDzyfJW5NUC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1-5zEAd_ve"
      },
      "source": [
        "# Working directory and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzPE7m2JkI3r",
        "outputId": "cf636ce4-560f-4ab0-f067-f043bd0b7b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Mount Google Drive at '/content/drive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcTPGmMHclaO",
        "outputId": "27a299e8-e2b5-4c73-c2df-93585d481451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# import and extract dataset\n",
        "\n",
        "import tarfile\n",
        "\n",
        "# Define the file_path variable with the actual path to your tar file\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtest_06-Nov-2007.tar\"  # Replace with the correct path\n",
        "\n",
        "# Open the tar file in read mode ('r')\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    # Extract all members of the archive to the current working directory\n",
        "    tar.extractall()\n",
        "    print('Done')\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtrainval_06-Nov-2007.tar\"  # Replace with the correct path\n",
        "\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    tar.extractall()\n",
        "    print('Done')\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/PyTorch Tutorial to Object Detection./VOCtrainval_11-May-2012.tar\"  # Replace with the correct path\n",
        "\n",
        "with tarfile.open(file_path, 'r') as tar:\n",
        "    tar.extractall()\n",
        "    print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b checkpoint-change --single-branch https://github.com/lzyjo/a-PyTorch-Tutorial-to-Object-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvwfRUhjM-Qm",
        "outputId": "b53e6a67-ea73-4d5d-ab27-56349edee174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'a-PyTorch-Tutorial-to-Object-Detection'...\n",
            "remote: Enumerating objects: 300, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 300 (delta 91), reused 68 (delta 60), pack-reused 181 (from 1)\u001b[K\n",
            "Receiving objects: 100% (300/300), 176.00 MiB | 22.35 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRzJn3EdQHNj",
        "outputId": "f5d3926c-0fc1-4869-b1d5-30f7599b2cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully moved '/content/VOCdevkit' to '/content/a-PyTorch-Tutorial-to-Object-Detection'\n"
          ]
        }
      ],
      "source": [
        "# prompt: move VOCdevkit folder into /content/a-PyTorch-Tutorial-to-Object-Detection-master\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"/content/VOCdevkit\"  # Replace with the actual path to your VOCdevkit folder\n",
        "destination_path = \"/content/a-PyTorch-Tutorial-to-Object-Detection\"\n",
        "\n",
        "# Check if the source directory exists\n",
        "if os.path.exists(source_path):\n",
        "    try:\n",
        "        # Use shutil.move to move the directory\n",
        "        shutil.move(source_path, destination_path)\n",
        "        print(f\"Successfully moved '{source_path}' to '{destination_path}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error moving directory: {e}\")\n",
        "else:\n",
        "    print(f\"Source directory '{source_path}' not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVOlFRtaR595",
        "outputId": "c5200bc9-4d14-4d6a-bb12-f8e60e8360c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection\n"
          ]
        }
      ],
      "source": [
        "%cd /content/a-PyTorch-Tutorial-to-Object-Detection\n",
        "#change cwd to appropriate one\n",
        "\n",
        "#don't need this but maybe useful for other projects:\n",
        "#!git clone https://github.com/lzyjo/a-PyTorch-Tutorial-to-Object-Detection.git #clone repo with all .py files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import utils"
      ],
      "metadata": {
        "id": "GoM-dOg1PKpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import * #includes from utils import create_data_lists for datalist creation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr7KaSIKi6gV",
        "outputId": "2d0ba4be-14f1-413f-ea64-c78ea032dd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/utils.py:570: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if d.__name__ is 'adjust_hue':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_data_lists(voc07_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2007',\n",
        "                  voc12_path='/content/a-PyTorch-Tutorial-to-Object-Detection/VOCdevkit/VOC2012',\n",
        "                  output_folder='/content/a-PyTorch-Tutorial-to-Object-Detection')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hgUuOIQsv2Q",
        "outputId": "978a65b7-a7dc-4a3e-b21f-8ae93e6c8836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 16551 training images containing a total of 49653 objects. Files have been saved to /content/a-PyTorch-Tutorial-to-Object-Detection.\n",
            "\n",
            "There are 4952 test images containing a total of 14856 objects. Files have been saved to /content/a-PyTorch-Tutorial-to-Object-Detection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import *\n",
        "from model import *"
      ],
      "metadata": {
        "id": "H9XV9EkitXng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from train import *"
      ],
      "metadata": {
        "id": "xDvmOtPh5BhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from eval import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3oRHtzhtfUh",
        "outputId": "f5ee8cce-5541-49ee-92ae-f4d08c99b523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/eval.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'model.SSD300' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1469: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detect import * #must change checkpoint file directory in detect.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMk0KyY6l7AN",
        "outputId": "bbcf2e20-0c0b-4673-b34e-53128ce74730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/a-PyTorch-Tutorial-to-Object-Detection/detect.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded checkpoint from epoch 232.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Torch CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdUkOL8r34lV",
        "outputId": "dcc15dc2-1b36-4cfd-b6ad-dca8f6160860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Using GPU.\n",
            "Torch CUDA version: 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate and Detect"
      ],
      "metadata": {
        "id": "uaZKzJpYPNrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "UhUdWqjFx0Pr",
        "outputId": "86230447-495d-49b7-b203-2fd9b21b6291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/78 [00:00<?, ?it/s]/content/a-PyTorch-Tutorial-to-Object-Detection/model.py:501: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
            "/content/a-PyTorch-Tutorial-to-Object-Detection/model.py:503: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  image_scores.append(class_scores[1 - suppress])\n",
            "Evaluating: 100%|██████████| 78/78 [06:18<00:00,  4.85s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "indices should be either on cpu or on the same device as the indexed tensor (cpu)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0a3b9d898ba5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/a-PyTorch-Tutorial-to-Object-Detection/eval.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(test_loader, model)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Calculate mAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mAPs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_mAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdet_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_difficulties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Print AP for each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/a-PyTorch-Tutorial-to-Object-Detection/utils.py\u001b[0m in \u001b[0;36mcalculate_mAP\u001b[0;34m(det_boxes, det_labels, det_scores, true_boxes, true_labels, true_difficulties)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;31m# 'ind' is the index of the object in these image-level tensors 'object_boxes', 'object_difficulties'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# In the original class-level tensors 'true_class_boxes', etc., 'ind' corresponds to object with index...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0moriginal_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_class_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_class_images\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mthis_image\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;31m# We need 'original_ind' to update 'true_class_boxes_detected'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/path/to/ima.ge'\n",
        "original_image = PIL.Image.open(img_path, mode='r')\n",
        "original_image = original_image.convert('RGB')\n",
        "\n",
        "detect(original_image, min_score=0.2, max_overlap=0.5, top_k=200).show() #detect(original_image, min_score, max_overlap, top_k, suppress=None)"
      ],
      "metadata": {
        "id": "Qy_R5emayZ7J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MzvBLQCKwwKU",
        "XMccxmZOwzcc",
        "LVgbA6lwDqLQ",
        "UW11MyYNIURS",
        "eSf0WOWvJjEh",
        "OROMHJITLoMx",
        "6Q6HpUa5MDeh",
        "4IhbRRNnMoBp",
        "0uwD4YI5N84Y",
        "TmVGBbN_hVfd"
      ],
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMVjGWhtYBULm3Rcxg5gIpL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}